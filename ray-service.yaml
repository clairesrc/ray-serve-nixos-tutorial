apiVersion: ray.io/v1
kind: RayService
metadata:
  name: ray-serve-tutorial
spec:
  serviceUnhealthySecondThreshold: 900
  deploymentUnhealthySecondThreshold: 300
  # serveConfigV2 takes a yaml multi-line string, which is the exact content of config.yaml
  serveConfigV2: |
    applications:
      - name: app1
        import_path: production_graph:app
        runtime_env:
          working_dir: "https://github.com/my-repo/ray_serve_tutorial/archive/master.zip"
          pip:
            - ray[serve]
            - torch
            - fastapi
            - starlette
            - requests
        deployments:
          - name: BatchModel
            num_replicas: 2
            ray_actor_options:
              num_cpus: 1
          - name: Ingress
            num_replicas: 1
            ray_actor_options:
              num_cpus: 0.1
  rayClusterConfig:
    rayVersion: '2.9.0' # Should match your Docker image version
    headGroupSpec:
      rayStartParams:
        dashboard-host: '0.0.0.0'
      template:
        spec:
          containers:
            - name: ray-head
              image: rayproject/ray:2.9.0-py310
              ports:
                - containerPort: 6379
                  name: gcs-server
                - containerPort: 8265 # Dashboard
                  name: dashboard
                - containerPort: 10001
                  name: client
                - containerPort: 8000
                  name: serve
              resources:
                limits:
                  cpu: "2"
                  memory: "4Gi"
                requests:
                  cpu: "2"
                  memory: "4Gi"
    workerGroupSpecs:
      - replicas: 1
        minReplicas: 1
        maxReplicas: 5
        groupName: small-group
        rayStartParams: {}
        template:
          spec:
            containers:
              - name: ray-worker
                image: rayproject/ray:2.9.0-py310
                lifecycle:
                  preStop:
                    exec:
                      command: ["/bin/sh","-c","ray stop"]
                # Liveness Probe: Restarts the pod if it hangs.
                livenessProbe:
                  exec:
                    command: ["/bin/sh", "-c", "ray health-check --address=127.0.0.1:6379"]
                  initialDelaySeconds: 30
                  periodSeconds: 60
                # Readiness Probe: Removes the pod from service endpoints if not ready.
                readinessProbe:
                  tcpSocket:
                    port: 8000 # Serve HTTP Port
                  initialDelaySeconds: 10
                  periodSeconds: 10
                resources:
                  limits:
                    cpu: "2"
                    memory: "4Gi"
                  requests:
                    cpu: "2"
                    memory: "4Gi"
